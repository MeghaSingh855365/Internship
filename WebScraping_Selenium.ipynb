{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb4a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing the selenium library\n",
    "#!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e817723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad14940",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location.You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 \n",
    "jobs data. This task will be done in following steps: \n",
    "1. First get the webpage https://www.naukri.com/ 2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the \n",
    "location” field. \n",
    "3. Then click the search button. \n",
    "4. Then scrape the data for the first 10 jobs results you get. \n",
    "5. Finally create a dataframe of the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39759752",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Administrator\\Downloads\\chromedriver.exe\")\n",
    "\n",
    "#specifiy the url of the webpage to be scrapped\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "#finding element for job search bar\n",
    "search_title=driver.find_element_by_xpath(\"//div[@class='inpWrap']/input[@id='qsb-keyword-sugg']\")\n",
    "search_title.send_keys('Data Analyst')\n",
    "search_location=driver.find_element_by_xpath(\"//div[@class='inpWrap']/input[@id='qsb-location-sugg']\")\n",
    "search_location.send_keys('Bangalore')\n",
    "\n",
    "#button click tag\n",
    "search=driver.find_element_by_xpath(\"//div[@class='search-btn']/button[@class='btn']\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12142b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skill</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Desgination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business Data Analyst - Database Design/Mining</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AugmatrixGo</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Shell</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Shell</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business Data Analyst - MIS &amp; Reporting</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>INTERTRUST GROUP</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>NetApp</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Analyst - SQL/Tableau/Redshift</td>\n",
       "      <td>Noida, Mumbai, Indore, Hyderabad/Secunderabad,...</td>\n",
       "      <td>Pronto Consulting Services</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Power BI - Data Analyst - Biocon Biologics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>BIOCON BIOLOGICS LIMITED</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Utthunga Technologies Pvt Ltd</td>\n",
       "      <td>3-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ID&amp;A - Data Analyst - Informatica MDM</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Shell</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Skill  \\\n",
       "0  Business Data Analyst - Database Design/Mining   \n",
       "1                                    Data Analyst   \n",
       "2                                    Data Analyst   \n",
       "3                                    Data Analyst   \n",
       "4         Business Data Analyst - MIS & Reporting   \n",
       "5                           Business Data Analyst   \n",
       "6      Senior Data Analyst - SQL/Tableau/Redshift   \n",
       "7      Power BI - Data Analyst - Biocon Biologics   \n",
       "8                             Senior Data Analyst   \n",
       "9           ID&A - Data Analyst - Informatica MDM   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                        Mumbai, Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6  Noida, Mumbai, Indore, Hyderabad/Secunderabad,...   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                    Company Name Desgination  \n",
       "0                    AugmatrixGo     2-5 Yrs  \n",
       "1              Applied Materials     0-3 Yrs  \n",
       "2                          Shell     5-8 Yrs  \n",
       "3                          Shell    5-10 Yrs  \n",
       "4               INTERTRUST GROUP     3-8 Yrs  \n",
       "5                         NetApp    5-10 Yrs  \n",
       "6     Pronto Consulting Services    6-10 Yrs  \n",
       "7       BIOCON BIOLOGICS LIMITED     3-8 Yrs  \n",
       "8  Utthunga Technologies Pvt Ltd     3-4 Yrs  \n",
       "9                          Shell     5-9 Yrs  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#empty list for all tags\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "job_experience=[]\n",
    "\n",
    "#extract the tags having the job-title\n",
    "title_tag=driver.find_elements_by_xpath(\"//div[@class='info fleft']//a[@class='title fw500 ellipsis']\")\n",
    "for i in title_tag:\n",
    "    job_title.append(i.text)\n",
    "\n",
    "#extract the tags having the job-location    \n",
    "company_location=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in company_location:\n",
    "        job_location.append(i.text)\n",
    "    \n",
    "#extract the tags having the job-name    \n",
    "job_name=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in job_name:\n",
    "        company_name.append(i.text)\n",
    "\n",
    "#extract the tags having the job-name \n",
    "job_exp=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "for i in job_exp:\n",
    "    job_experience.append(i.text)\n",
    "    \n",
    "#length of allthe tags\n",
    "print(len(job_title),len(job_location),len(company_name),len(job_experience)) \n",
    "\n",
    "#Making DataFrame for 10 job postion\n",
    "import pandas as pd\n",
    "Scrapped_data=pd.DataFrame({})\n",
    "Scrapped_data['Skill']=job_title[:10]\n",
    "Scrapped_data['Job Location']=job_location[:10]\n",
    "Scrapped_data['Company Name']=company_name[:10]\n",
    "Scrapped_data['Desgination']=job_experience[:10]\n",
    "Scrapped_data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522a3c1a",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data. \n",
    "This task will be done in following steps: \n",
    "1. First get the webpage https://www.naukri.com/ 2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the \n",
    "location” field. \n",
    "3. Then click the search button. \n",
    "4. Then scrape the data for the first 10 jobs results you get. \n",
    "5. Finally create a dataframe of the scraped data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d917993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_titles</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>Job_link</th>\n",
       "      <th>job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Forecasting Analyst/ Data Scientist (US Client)</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru\\n(WFH du...</td>\n",
       "      <td>Concentrix Daksh Services</td>\n",
       "      <td>https://www.naukri.com/job-listings-forecastin...</td>\n",
       "      <td>Job description - Roles and Responsibilities -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Oracle India Pvt. Ltd.</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-scien...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Kwalee India Pvt Ltd.</td>\n",
       "      <td>https://www.naukri.com/job-listings-senior-dat...</td>\n",
       "      <td>Job description - Kwalee is one of the world's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru(Sadashiva Nagar)\\n(WFH dur...</td>\n",
       "      <td>Convergence Infotech Ltd</td>\n",
       "      <td>https://www.naukri.com/job-listings-senior-dat...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist | Fortune 500 Supermarke...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>TALENT500 TECH (INDIA) PRIVATE LIMITED</td>\n",
       "      <td>https://www.naukri.com/job-listings-senior-dat...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Visa</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-scien...</td>\n",
       "      <td>Job description - Essential Functions - Serve ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "      <td>TransOrg Solutions Services (P) Ltd.</td>\n",
       "      <td>https://www.naukri.com/job-listings-lead-data-...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist / Tech Lead - SQL / Pyth...</td>\n",
       "      <td>Pune, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Exploro Solutions</td>\n",
       "      <td>https://www.naukri.com/job-listings-senior-dat...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior / Lead Data Scientist</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru</td>\n",
       "      <td>CoreEdge Solutions</td>\n",
       "      <td>https://www.naukri.com/job-listings-senior-lea...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Looking For Senior Data Scientist Immediate Jo...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>https://www.naukri.com/job-listings-looking-fo...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          job_titles  \\\n",
       "0    Forecasting Analyst/ Data Scientist (US Client)   \n",
       "1                                     Data Scientist   \n",
       "2                              Senior Data Scientist   \n",
       "3                              Senior Data Scientist   \n",
       "4  Senior Data Scientist | Fortune 500 Supermarke...   \n",
       "5                                     Data Scientist   \n",
       "6                                Lead Data Scientist   \n",
       "7  Senior Data Scientist / Tech Lead - SQL / Pyth...   \n",
       "8                       Senior / Lead Data Scientist   \n",
       "9  Looking For Senior Data Scientist Immediate Jo...   \n",
       "\n",
       "                                        job_location  \\\n",
       "0  Gurgaon/Gurugram, Bangalore/Bengaluru\\n(WFH du...   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3  Bangalore/Bengaluru(Sadashiva Nagar)\\n(WFH dur...   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...   \n",
       "7                 Pune, Chennai, Bangalore/Bengaluru   \n",
       "8  Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                              company_name  \\\n",
       "0                Concentrix Daksh Services   \n",
       "1                   Oracle India Pvt. Ltd.   \n",
       "2                    Kwalee India Pvt Ltd.   \n",
       "3                 Convergence Infotech Ltd   \n",
       "4   TALENT500 TECH (INDIA) PRIVATE LIMITED   \n",
       "5                                     Visa   \n",
       "6     TransOrg Solutions Services (P) Ltd.   \n",
       "7                        Exploro Solutions   \n",
       "8                       CoreEdge Solutions   \n",
       "9  Mount Talent Consulting Private Limited   \n",
       "\n",
       "                                            Job_link  \\\n",
       "0  https://www.naukri.com/job-listings-forecastin...   \n",
       "1  https://www.naukri.com/job-listings-data-scien...   \n",
       "2  https://www.naukri.com/job-listings-senior-dat...   \n",
       "3  https://www.naukri.com/job-listings-senior-dat...   \n",
       "4  https://www.naukri.com/job-listings-senior-dat...   \n",
       "5  https://www.naukri.com/job-listings-data-scien...   \n",
       "6  https://www.naukri.com/job-listings-lead-data-...   \n",
       "7  https://www.naukri.com/job-listings-senior-dat...   \n",
       "8  https://www.naukri.com/job-listings-senior-lea...   \n",
       "9  https://www.naukri.com/job-listings-looking-fo...   \n",
       "\n",
       "                                     job_description  \n",
       "0  Job description - Roles and Responsibilities -...  \n",
       "1                                                 NA  \n",
       "2  Job description - Kwalee is one of the world's...  \n",
       "3                                                 NA  \n",
       "4                                                 NA  \n",
       "5  Job description - Essential Functions - Serve ...  \n",
       "6                                                 NA  \n",
       "7                                                 NA  \n",
       "8                                                 NA  \n",
       "9                                                 NA  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connecting the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Administrator\\Downloads\\chromedriver.exe\")\n",
    "\n",
    "#specifiy the url of the webpage to be scrapped\n",
    "url='https://www.naukri.com/data-scientist-jobs-in-bangalore?k=data%20scientist&l=bangalore'\n",
    "driver.get(url)\n",
    "#calling empty list to store the different data\n",
    "job_titles=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "job_description=[]\n",
    "Job_link=[]\n",
    "\n",
    "#extract the tags having the job-title \n",
    "title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for j in title_tags[:10]:\n",
    "    job_titles.append(j.text)\n",
    "    \n",
    "#extracting the tags having the location \n",
    "location_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for j in location_tags[:10]:\n",
    "    job_location.append(j.text)\n",
    "    \n",
    "#extracting the tags having the company name\n",
    "company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for j in company_tags[:10]:\n",
    "    company_name.append(j.text)\n",
    "    \n",
    "# extracting the tags having the each job link\n",
    "url_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for j in url_tags[:10]:\n",
    "    Job_link.append(j.get_attribute('href'))\n",
    "#Making for loop for extracting description of a job\n",
    "for j in Job_link:\n",
    "    driver.get(j)\n",
    "    try:\n",
    "        job_description.append((driver.find_element_by_xpath(\"//section[@class='job-desc']\")).text)\n",
    "    except NoSuchElementException:\n",
    "        job_description.append(\"NA\")\n",
    "        \n",
    "#length of the tag\n",
    "print(len(job_titles),len(job_location),len(company_name),len(job_description),len(Job_link))\n",
    "\n",
    "import pandas as pd\n",
    "##Making DataFrame for 10 job postion\n",
    "Data_scientist=pd.DataFrame({})\n",
    "Data_scientist['job_titles']=job_titles\n",
    "Data_scientist['job_location']=job_location\n",
    "Data_scientist['company_name']=company_name\n",
    "Data_scientist['Job_link']=Job_link\n",
    "Data_scientist['job_description']=job_description\n",
    "Data_scientist['job_description']=Data_scientist['job_description'].str.replace('\\n',' - ')\n",
    "Data_scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b57329e",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below: \n",
    "You have to use the location and salary filter. \n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results. \n",
    "You have to scrape the job-title, job-location, company name, experience required. \n",
    "The location filter to be used is “Delhi/NCR” The salary filter to be used is “3-6” lakhs \n",
    "The task will be done as shown in the below steps: \n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field. \n",
    "3. Then click the search button. \n",
    "4. Then apply the location filter and salary filter by checking the respective boxes \n",
    "5. Then scrape the data for the first 10 jobs results you get. \n",
    "6. Finally create a dataframe of the scraped data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "76523011",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Administrator\\Downloads\\chromedriver.exe\")\n",
    "#calling site\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "#extraction preocess\n",
    "search_bar=driver.find_element_by_id(\"qsb-keyword-sugg\") #search bar\n",
    "search_bar.clear()  #clearing search bar\n",
    "search_bar.send_keys(\"Data Scientist\")   #inserting \"Data science\" in search bar\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click() #clicking on search button\n",
    "time.sleep(4)\n",
    "driver.find_element_by_xpath('//*[@title=\"Delhi / NCR\"]').click()   #setting location filter delhi\n",
    "time.sleep(4)\n",
    "driver.find_element_by_xpath('//*[@title=\"3-6 Lakhs\"]').click()   #setting salary\n",
    "time.sleep(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f8af9fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Experiance_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kochi/Cochin, Kolkata, Hyderabad/Secunderabad,...</td>\n",
       "      <td>Think i</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Pune, Bangalore/Bengaluru, Delhi / NCR\\n(WFH d...</td>\n",
       "      <td>ThinkBumblebee Analytics Pvt. Ltd.</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist III-2</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Concentrix Daksh Services</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Job Opportunity || Data Scientist || HCL Techn...</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>HCL Technologies</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida(Sector-126 Noida)</td>\n",
       "      <td>MoMagic Technologies Pvt. Ltd.</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida(Sector-126 Noida)</td>\n",
       "      <td>MoMagic Technologies Pvt. Ltd.</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Urgent Hiring || Data Scientist || Delhi</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>Shriram Automall India Limited</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>SVK Global Solutions Private Limited</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Academic Counsellor - Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>GreatLearning</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title  \\\n",
       "0                                     Data Scientist   \n",
       "1                                     Data Scientist   \n",
       "2                               Data Scientist III-2   \n",
       "3  Job Opportunity || Data Scientist || HCL Techn...   \n",
       "4                                     Data Scientist   \n",
       "5                                     Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7           Urgent Hiring || Data Scientist || Delhi   \n",
       "8                                     Data Scientist   \n",
       "9               Academic Counsellor - Data Scientist   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Kochi/Cochin, Kolkata, Hyderabad/Secunderabad,...   \n",
       "1  Pune, Bangalore/Bengaluru, Delhi / NCR\\n(WFH d...   \n",
       "2                                   Gurgaon/Gurugram   \n",
       "3                                        Delhi / NCR   \n",
       "4      Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "5                            Noida(Sector-126 Noida)   \n",
       "6                            Noida(Sector-126 Noida)   \n",
       "7                                        Delhi / NCR   \n",
       "8                                              Noida   \n",
       "9              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "\n",
       "                           Company_Name Experiance_required  \n",
       "0                               Think i             0-2 Yrs  \n",
       "1    ThinkBumblebee Analytics Pvt. Ltd.             2-6 Yrs  \n",
       "2             Concentrix Daksh Services             3-8 Yrs  \n",
       "3                      HCL Technologies             4-7 Yrs  \n",
       "4                     Fractal Analytics             3-7 Yrs  \n",
       "5        MoMagic Technologies Pvt. Ltd.             4-6 Yrs  \n",
       "6        MoMagic Technologies Pvt. Ltd.             4-6 Yrs  \n",
       "7        Shriram Automall India Limited             2-7 Yrs  \n",
       "8  SVK Global Solutions Private Limited            6-10 Yrs  \n",
       "9                         GreatLearning             1-4 Yrs  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extracting the required data\n",
    "titles=[] #empty list for job_title\n",
    "location=[] #empty list for location\n",
    "company=[] #empty list for company name\n",
    "exprience=[] #empty list for experiance_requires\n",
    "\n",
    "\n",
    "#job_title\n",
    "title=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title:\n",
    "    titles.append(i.text)\n",
    "titles=titles[:10]\n",
    "\n",
    "#location\n",
    "locationElement=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in locationElement:\n",
    "    location.append(i.text)\n",
    "location=location[:10]\n",
    "\n",
    "#company_name\n",
    "companyElement=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in companyElement:\n",
    "    company.append(i.text)\n",
    "company=company[:10]\n",
    "\n",
    "#experiance_required\n",
    "expr=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in expr:\n",
    "    exprience.append(i.text)\n",
    "exprience=exprience[:10]\n",
    "\n",
    "driver.close()\n",
    "#Making DataFrame\n",
    "df=pd.DataFrame({})\n",
    "df[\"Job_Title\"]=titles\n",
    "df[\"Location\"]=location\n",
    "df[\"Company_Name\"]=company\n",
    "df[\"Experiance_required\"]=exprience\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6359aca",
   "metadata": {},
   "source": [
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes: \n",
    "1. Brand \n",
    "2. Product Description \n",
    "3. Price \n",
    "The attributes which you have to scrape is ticked marked in the below image. \n",
    "To scrape the data you have to go through following steps: \n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and \n",
    "click the search icon \n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the \n",
    "required data as usual. \n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom of the page , then \n",
    "click on it. \n",
    "5. Now scrape data from this page as usual \n",
    "6. Repeat this until you get data for 100 sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "912d05e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Administrator\\Downloads\\chromedriver.exe\")\n",
    "#getting Url\n",
    "url=\"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "#finding element for job search bar\n",
    "search_bar=driver.find_element_by_class_name(\"_3704LK\")\n",
    "search_bar.send_keys('sunglasses')\n",
    "#click on search button:\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c548a258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120 120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹248</td>\n",
       "      <td>90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹513</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (56)</td>\n",
       "      <td>₹188</td>\n",
       "      <td>85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Round Sungl...</td>\n",
       "      <td>₹276</td>\n",
       "      <td>83%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹200</td>\n",
       "      <td>87%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>UV Protection, Mirrored Retro Square Sunglasse...</td>\n",
       "      <td>₹311</td>\n",
       "      <td>84%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>UV Protection, Riding Glasses Aviator Sunglass...</td>\n",
       "      <td>₹296</td>\n",
       "      <td>85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Singco</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹526</td>\n",
       "      <td>73%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>hipe</td>\n",
       "      <td>UV Protection, Gradient, Riding Glasses Wayfar...</td>\n",
       "      <td>₹233</td>\n",
       "      <td>76%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection Sports Sunglasses (73)</td>\n",
       "      <td>₹330</td>\n",
       "      <td>73%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Brand                                        Description Price  \\\n",
       "0    Elligator                UV Protection Round Sunglasses (54)  ₹248   \n",
       "1     Fastrack   UV Protection Rectangular Sunglasses (Free Size)  ₹513   \n",
       "2         SRPM             UV Protection Wayfarer Sunglasses (56)  ₹188   \n",
       "3       SUNBEE  UV Protection, Polarized, Mirrored Round Sungl...  ₹276   \n",
       "4       PIRASO              UV Protection Aviator Sunglasses (54)  ₹200   \n",
       "..         ...                                                ...   ...   \n",
       "95  PHENOMENAL  UV Protection, Mirrored Retro Square Sunglasse...  ₹311   \n",
       "96      GANSTA  UV Protection, Riding Glasses Aviator Sunglass...  ₹296   \n",
       "97      Singco       UV Protection Aviator Sunglasses (Free Size)  ₹526   \n",
       "98        hipe  UV Protection, Gradient, Riding Glasses Wayfar...  ₹233   \n",
       "99       NuVew               UV Protection Sports Sunglasses (73)  ₹330   \n",
       "\n",
       "   Discount  \n",
       "0       90%  \n",
       "1       35%  \n",
       "2       85%  \n",
       "3       83%  \n",
       "4       87%  \n",
       "..      ...  \n",
       "95      84%  \n",
       "96      85%  \n",
       "97      73%  \n",
       "98      76%  \n",
       "99      73%  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calling empty list to store the different data\n",
    "brands = []\n",
    "descriptions = []\n",
    "prices = []\n",
    "discounts = []\n",
    "\n",
    "#Making loop to get first 3 pages to get 100 products value\n",
    "for i in range(0,3):\n",
    "    time.sleep(5)\n",
    "    #getting the information div by class\n",
    "    divClass = driver.find_elements_by_class_name('_2B099V')\n",
    "    \n",
    "    #making loop to get the value from div class\n",
    "    for i in divClass:\n",
    "        #appending info to the currsponding lists\n",
    "        brands.append(i.find_element_by_class_name('_2WkVRV').text)\n",
    "        descriptions.append(i.find_element_by_class_name('IRpwTa').text)\n",
    "        prices.append(i.find_element_by_class_name('_30jeq3').text)\n",
    "        discounts.append(i.find_element_by_class_name('_3Ay6Sb').text.strip(\" off\"))\n",
    "    next_page = driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "    try:\n",
    "        #go to next page\n",
    "        driver.get(next_page[1].get_attribute('href'))\n",
    "    except:\n",
    "        driver.get(next_page[0].get_attribute('href'))\n",
    "print(len(brands),len(descriptions),len(prices),len(discounts))\n",
    "#creating dataframe\n",
    "sunglasses = pd.DataFrame({'Brand':brands[:100],\n",
    "                'Description':descriptions[:100],\n",
    "                'Price':prices[:100],\n",
    "                'Discount':discounts[:100]})\n",
    "sunglasses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008bfecd",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: \n",
    "http://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.\n",
    "When you will open the above link you will reach to the below shown webpage .\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are: \n",
    "1. Rating \n",
    "2. Review_summary \n",
    "3. Full review \n",
    "4. You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cb9012d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[110, 110, 110]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RATING</th>\n",
       "      <th>REVIEW SUMMARY</th>\n",
       "      <th>FULL REVIEW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money  New Line:   New ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.  New Line...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>i11 is worthy to buy, too much happy with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RATING       REVIEW SUMMARY  \\\n",
       "0       5            Brilliant   \n",
       "1       5       Simply awesome   \n",
       "2       5     Perfect product!   \n",
       "3       5    Worth every penny   \n",
       "4       5            Fabulous!   \n",
       "..    ...                  ...   \n",
       "95      5  Best in the market!   \n",
       "96      5        Great product   \n",
       "97      4          Good choice   \n",
       "98      5    Worth every penny   \n",
       "99      5   Highly recommended   \n",
       "\n",
       "                                          FULL REVIEW  \n",
       "0   The Best Phone for the Money  New Line:   New ...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Amazing phone with great cameras and better ba...  \n",
       "3   Previously I was using one plus 3t it was a gr...  \n",
       "4   This is my first iOS phone. I am very happy wi...  \n",
       "..                                                ...  \n",
       "95  Great iPhone very snappy experience as apple k...  \n",
       "96  Amazing Powerful and Durable Gadget.  New Line...  \n",
       "97  So far it’s been an AMAZING experience coming ...  \n",
       "98  i11 is worthy to buy, too much happy with the ...  \n",
       "99  iphone 11 is a very good phone to buy only if ...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connecting the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Administrator\\Downloads\\chromedriver.exe\")\n",
    "#getting Url\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includesearpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC\")\n",
    "\n",
    "#finding element for review\n",
    "all_reviews_btn=driver.find_element_by_xpath(\"//div[@class='_3UAT2v _16PBlm']/span\")\n",
    "all_reviews_btn.click()\n",
    "        \n",
    "def scrape_rating():\n",
    "    rating=[]\n",
    "    driver.refresh()\n",
    "    rating_el=driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "    time.sleep(3)\n",
    "    for i in rating_el:\n",
    "        try:\n",
    "            rating.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "        except:\n",
    "            rating.append(\"--\")\n",
    "    return rating\n",
    "\n",
    "def scrape_review_summary():\n",
    "    review_sum=[]\n",
    "    driver.refresh()\n",
    "    rev_sum=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "    time.sleep(3)\n",
    "    for i in rev_sum:\n",
    "        try:\n",
    "            review_sum.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "        except:\n",
    "            review_sum.append(\"--\")\n",
    "    return review_sum\n",
    "\n",
    "def scrape_full_review():\n",
    "    full_review=[]\n",
    "    driver.refresh()\n",
    "    rev_el=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']/div\")\n",
    "    time.sleep(3)\n",
    "    for i in rev_el:\n",
    "        try:\n",
    "            full_review.append(i.text.replace(\"\\n\",\"  New Line: \"))\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "        except:\n",
    "            full_review.append(\"--\")\n",
    "    return full_review\n",
    "#calling empty list to store the different data\n",
    "rating=[]\n",
    "review_sum=[]\n",
    "full_review=[]\n",
    "length=len(rating)\n",
    "while(length<=100):\n",
    "    driver.refresh()\n",
    "    rating.extend(scrape_rating())\n",
    "    review_sum.extend(scrape_review_summary())\n",
    "    full_review.extend(scrape_full_review())\n",
    "    time.sleep(5)\n",
    "    length=len(rating)\n",
    "    next_btn=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']/span\")\n",
    "    next_btn.click()\n",
    "    \n",
    "#length of the dataset\n",
    "length_list=[len(full_review),len(rating),len(review_sum)]\n",
    "print(length_list)\n",
    "\n",
    "#creating a DataFrame for the dataset\n",
    "import pandas as pd\n",
    "df6=pd.DataFrame()\n",
    "df6[\"RATING\"]=rating[:100]\n",
    "df6[\"REVIEW SUMMARY\"]=review_sum[:100]\n",
    "df6[\"FULL REVIEW\"]=full_review[:100]\n",
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2dd2ff",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field. \n",
    "You have to scrape 4 attributes of each sneaker: \n",
    "1. Brand \n",
    "2. Product Description \n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f0ae2528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOOTGRAB</td>\n",
       "      <td>White Boots || High Tops || Sneakers For Men</td>\n",
       "      <td>₹549</td>\n",
       "      <td>45% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹479</td>\n",
       "      <td>63% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹398</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCATCHITE</td>\n",
       "      <td>Sneakers Sneakers For Men</td>\n",
       "      <td>₹398</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Super Stylish &amp; Trendy Combo Pack of 02 Pairs ...</td>\n",
       "      <td>₹699</td>\n",
       "      <td>56% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Kraasa</td>\n",
       "      <td>Casual , Partywear Sneakers Shoes For Men's An...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Edoeviv</td>\n",
       "      <td>Unique &amp; Perfect Collection Combo Pack of 02 S...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>37% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Shoes Bank</td>\n",
       "      <td>casual for men (beige 06) Sneakers For Men</td>\n",
       "      <td>₹345</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>CALCADOS</td>\n",
       "      <td>Combo Pack Of 2 Latest Stylish Casual Shoes fo...</td>\n",
       "      <td>₹899</td>\n",
       "      <td>54% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>T-ROCK</td>\n",
       "      <td>Fashion Outdoor Canvas Casual Light Weight Lac...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Brand                                Product_description Price  \\\n",
       "0     FOOTGRAB       White Boots || High Tops || Sneakers For Men  ₹549   \n",
       "1      Numenzo                                   Sneakers For Men  ₹479   \n",
       "2     Magnolia                                   Sneakers For Men  ₹398   \n",
       "3    SCATCHITE                          Sneakers Sneakers For Men  ₹398   \n",
       "4       Chevit  Super Stylish & Trendy Combo Pack of 02 Pairs ...  ₹699   \n",
       "..         ...                                                ...   ...   \n",
       "95      Kraasa  Casual , Partywear Sneakers Shoes For Men's An...  ₹499   \n",
       "96     Edoeviv  Unique & Perfect Collection Combo Pack of 02 S...  ₹499   \n",
       "97  Shoes Bank         casual for men (beige 06) Sneakers For Men  ₹345   \n",
       "98    CALCADOS  Combo Pack Of 2 Latest Stylish Casual Shoes fo...  ₹899   \n",
       "99      T-ROCK  Fashion Outdoor Canvas Casual Light Weight Lac...  ₹399   \n",
       "\n",
       "   Discount  \n",
       "0   45% off  \n",
       "1   63% off  \n",
       "2   60% off  \n",
       "3   60% off  \n",
       "4   56% off  \n",
       "..      ...  \n",
       "95  50% off  \n",
       "96  37% off  \n",
       "97  65% off  \n",
       "98  54% off  \n",
       "99  60% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connecting the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Administrator\\Downloads\\chromedriver.exe\")\n",
    "#getting Url\n",
    "url=\"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "#finding element for job search bar\n",
    "driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]').click()\n",
    "time.sleep(2)\n",
    "#finding element for job search bar\n",
    "search_bar=driver.find_element_by_xpath('//*[@title=\"Search for products, brands and more\"]')   \n",
    "search_bar.click()\n",
    "search_bar.send_keys(\"sneakers\")  \n",
    "\n",
    "#click on search button to get the value of search bar\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search_btn.click()\n",
    "\n",
    "time.sleep(4)\n",
    "#calling empty list to store the different data\n",
    "brand=[]  \n",
    "product_description=[]   \n",
    "price=[] \n",
    "discount=[] \n",
    "\n",
    "for i in range(0,4):   #Selecting top 4 page from the flipkart\n",
    "    for j in driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]'):   #Making for loop for extracting description of a brand\n",
    "        brand.append(j.text)\n",
    "    for k in driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]'):      #Making for loop for extracting description of a product_description\n",
    "        product_description.append(k.text)\n",
    "\n",
    "    for l in driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]'):   #Making for loop for extracting description of a price\n",
    "        price.append(l.text)\n",
    "\n",
    "    for m in driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]'):   #Making for loop for extracting description of a discount\n",
    "        discount.append(m.text)\n",
    "    driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]').click()      #Clickcing on the next page\n",
    "    time.sleep(5)\n",
    "\n",
    "#selecting top 100 \n",
    "brand=brand[:100]\n",
    "product_description=product_description[:100]\n",
    "price=price[:100]\n",
    "discount=discount[:100]\n",
    "\n",
    "driver.close()\n",
    "#Making DataFrame\n",
    "df=pd.DataFrame({})\n",
    "df[\"Brand\"]=brand\n",
    "df[\"Product_description\"]=product_description\n",
    "df[\"Price\"]=price\n",
    "df[\"Discount\"]=discount\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f457e6d",
   "metadata": {},
   "source": [
    "# Q7: Go to the link - https://www.myntra.com/shoes Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, as shown in the below image.\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe as shown in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cb0dfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Brand                           Description Price\n",
      "0               H&M                   Chunky Combat Boots  2699\n",
      "1            ADIDAS        Men Woven Design Running Shoes  2009\n",
      "2        Eego Italy                    Men Trekking Shoes   899\n",
      "3   PUMA Motorsport  Unisex Sf Drift Cat 5 Ultra Sneakers  3149\n",
      "4           ZAPATOZ                    Women Heeled Boots   699\n",
      "..              ...                                   ...   ...\n",
      "95         Histeria                 Men Synthetic Loafers   699\n",
      "96  U.S. Polo Assn.                    Men Solid Sneakers  2199\n",
      "97       Marc Loire                           Women Pumps   983\n",
      "98         AfroJack                  Men Slip-On Sneakers   681\n",
      "99              H&M                           Women Boots  4499\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#connecting the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Administrator\\Downloads\\chromedriver.exe\")\n",
    "url = \"https://www.myntra.com/shoes\"\n",
    "#go to myntra shoe section\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "#clicking the filter condition checkboxes\n",
    "price_el = driver.find_element_by_class_name(\"price-list\")\n",
    "price_el.find_elements_by_tag_name(\"li\")[1].click()\n",
    "driver.find_elements_by_class_name(\"colour-listItem\")[0].click()\n",
    "\n",
    "#initilize product info lists\n",
    "brands = []\n",
    "descriptions = []\n",
    "prices = []\n",
    "#looping to get 100 products(50 products/page)\n",
    "for i in range(0,2):\n",
    "    time.sleep(5)\n",
    "    #getting the information div by class\n",
    "    divs = driver.find_elements_by_class_name('product-productMetaInfo')\n",
    "    for div in divs:\n",
    "        #appending info to the lists\n",
    "        brands.append(div.find_element_by_class_name('product-brand').text)\n",
    "        descriptions.append(div.find_element_by_class_name('product-product').text)\n",
    "        prices.append(div.find_element_by_class_name(\"product-price\").text.split(\".\")[1].split(\"Rs\")[0].strip())\n",
    "    next_page = driver.find_elements_by_xpath(\"//a[@rel='next']\")\n",
    "    try:\n",
    "        driver.get(next_page[1].get_attribute('href'))\n",
    "    except:\n",
    "        driver.get(next_page[0].get_attribute('href'))\n",
    "\n",
    "# creating dataframe\n",
    "shoes = pd.DataFrame({'Brand':brands[:100],\n",
    "                'Description':descriptions[:100],\n",
    "                'Price':prices[:100]})\n",
    "print(shoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0a7a82",
   "metadata": {},
   "source": [
    "# Q8: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. \n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the below image: \n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop: \n",
    "1. Title \n",
    "2. Ratings \n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5ad1a11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>RATING</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP Pavilion Aero Ultra Thin &amp; Light 13.3-inch(...</td>\n",
       "      <td>00</td>\n",
       "      <td>74,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP Pavilion 15 Ryzen 5 15.6-inch (39.6 cms) Th...</td>\n",
       "      <td>00</td>\n",
       "      <td>57,023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo IdeaPad Slim 1 Intel Celeron N4020 11.6...</td>\n",
       "      <td>00</td>\n",
       "      <td>27,857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP 15 (2021) Thin &amp; Light 10th Gen Intel Core ...</td>\n",
       "      <td>00</td>\n",
       "      <td>43,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Chromebook 14-inch (35.56 cms) Thin &amp; Light...</td>\n",
       "      <td>00</td>\n",
       "      <td>27,567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP 15 10th Gen Intel Core i3 Thin and Light 15...</td>\n",
       "      <td>00</td>\n",
       "      <td>62,290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS Computer Notebook 14(2020) Intel Quad Cor...</td>\n",
       "      <td>00</td>\n",
       "      <td>40,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AVITA Cosmos 2 in 1 Celeron Dual Core - (4 GB/...</td>\n",
       "      <td>00</td>\n",
       "      <td>26,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dell 15 (2021) Athlon Silver 3050U Laptop, 4GB...</td>\n",
       "      <td>00</td>\n",
       "      <td>15,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 Intel Celeron N4020 14\" ...</td>\n",
       "      <td>00</td>\n",
       "      <td>33,449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               TITLE RATING   PRICE\n",
       "0  HP Pavilion Aero Ultra Thin & Light 13.3-inch(...     00  74,490\n",
       "1  HP Pavilion 15 Ryzen 5 15.6-inch (39.6 cms) Th...     00  57,023\n",
       "2  Lenovo IdeaPad Slim 1 Intel Celeron N4020 11.6...     00  27,857\n",
       "3  HP 15 (2021) Thin & Light 10th Gen Intel Core ...     00  43,990\n",
       "4  HP Chromebook 14-inch (35.56 cms) Thin & Light...     00  27,567\n",
       "5  HP 15 10th Gen Intel Core i3 Thin and Light 15...     00  62,290\n",
       "6  ASUS Computer Notebook 14(2020) Intel Quad Cor...     00  40,990\n",
       "7  AVITA Cosmos 2 in 1 Celeron Dual Core - (4 GB/...     00  26,990\n",
       "8  Dell 15 (2021) Athlon Silver 3050U Laptop, 4GB...     00  15,990\n",
       "9  Lenovo IdeaPad Slim 3 Intel Celeron N4020 14\" ...     00  33,449"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connecting the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Administrator\\Downloads\\chromedriver.exe\")\n",
    "driver.get(\"https://www.amazon.in/\")\n",
    "\n",
    "search=driver.find_element_by_xpath(\"//input[@class='nav-input nav-progressive-attribute']\")\n",
    "search.send_keys('laptop')\n",
    "\n",
    "search_button=driver.find_elements_by_xpath(\"//input[@class='nav-input nav-progressive-attribute']\")\n",
    "search_button[1].click()\n",
    "\n",
    "titleElement=driver.find_elements_by_xpath(\"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']\")\n",
    "title=[]\n",
    "for i in titleElement[:10]:\n",
    "    title.append(i.text)\n",
    "\n",
    "priceElement=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "price=[]\n",
    "for i in priceElement[:10]:\n",
    "    price.append(i.text)\n",
    "\n",
    "url=driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\")\n",
    "\n",
    "rating_url=[]\n",
    "for i in url[:10]:\n",
    "    rating_url.append(i.get_attribute('href'))\n",
    "    \n",
    "rating=[]\n",
    "for i in rating_url[:10]:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        \n",
    "        ratings = driver.find_element(By.XPATH,\".//span[@class='a-icon-alt']/..\")\n",
    "        ratings = ratings.get_attribute('innerHTML').split(\">\")[1].split(\" \")[0]\n",
    "        rating.append(ratings)\n",
    "    except:\n",
    "        \n",
    "        \n",
    "        rating.append(\"00\")\n",
    "        \n",
    "#creating DataFrame for the scraped data\n",
    "import pandas as pd\n",
    "laptop_df=pd.DataFrame()\n",
    "#laptop_df['INDEX']=range(1,11)\n",
    "laptop_df['TITLE']=title[:10]\n",
    "laptop_df['RATING']=rating[:10]\n",
    "laptop_df['PRICE']=price[:10]\n",
    "laptop_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650874d5",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida location. You have to scrape company name, No. of days ago when job was posted, Rating of the company. \n",
    "This task will be done in following steps: \n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the Job option as shown in the image \n",
    "3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter \n",
    "“Data Scientist” and click on search button. \n",
    "4. You will reach to the following web page click on location and in place of “Search location” enter \n",
    "“Noida” and select location “Noida”.\n",
    "5. Then scrape the data for the first 10 jobs results you get on the above shown page. \n",
    "6. Finally create a dataframe of the scraped data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "097c681b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Administrator\\Downloads\\chromedriver.exe\")\n",
    "\n",
    "#specifiy the url of the webpage to be scrapped\n",
    "driver.get(\"https://www.ambitionbox.com/jobs\")\n",
    "\n",
    "#finding element for job search bar\n",
    "job_search=driver.find_element_by_xpath(\"//a[@title='Jobs']\")\n",
    "job_search.click()\n",
    "\n",
    "#finding web element and search as required\n",
    "search_element = driver.find_element_by_name('ab_jobsSearch')\n",
    "search_element.send_keys(\"Data Scientist\")\n",
    "\n",
    "#Clicking on the button\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='ab_btn search-btn round']\")\n",
    "search_btn.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "118b6707",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on location bar\n",
    "loc_search = driver.find_element(By.XPATH,\"//div[@title='Location']/p\").click()\n",
    "\n",
    "#clicking on location Noida\n",
    "search_loc = driver.find_element(By.XPATH,\"//input[@placeholder='Search locations']\")  \n",
    "search_loc.send_keys(\"Noida\")\n",
    "\n",
    "#click on Noida for search of location\n",
    "loc_srch = driver.find_element(By.XPATH,\"//input[@id='location_Noida']\").click()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8a12b0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>No. of days ago when job was posted</th>\n",
       "      <th>Company Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>8d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Steria India Ltd</td>\n",
       "      <td>21hr ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ameriprise Financial</td>\n",
       "      <td>3d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jubilant Foodworks Limited</td>\n",
       "      <td>6hr ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>29d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Steria India Ltd</td>\n",
       "      <td>20d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Steria India Ltd</td>\n",
       "      <td>20d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HCL Technologies Limited</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Zyoin</td>\n",
       "      <td>2d ago</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GI Group</td>\n",
       "      <td>2hr ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Company Name  \\\n",
       "0  Optum Global Solutions (India) Private Limited   \n",
       "1                                Steria India Ltd   \n",
       "2                            Ameriprise Financial   \n",
       "3                      Jubilant Foodworks Limited   \n",
       "4  Optum Global Solutions (India) Private Limited   \n",
       "5                                Steria India Ltd   \n",
       "6                                Steria India Ltd   \n",
       "7                        HCL Technologies Limited   \n",
       "8                                           Zyoin   \n",
       "9                                        GI Group   \n",
       "\n",
       "  No. of days ago when job was posted Company Rating  \n",
       "0                              8d ago            4.1  \n",
       "1                            21hr ago            4.1  \n",
       "2                              3d ago            4.1  \n",
       "3                             6hr ago            3.9  \n",
       "4                             29d ago            4.1  \n",
       "5                             20d ago            4.1  \n",
       "6                             20d ago            4.1  \n",
       "7                            1mon ago            3.8  \n",
       "8                              2d ago            4.2  \n",
       "9                             2hr ago            3.9  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calling empty list to store the different data\n",
    "Company_Name =[]   \n",
    "Days =[]\n",
    "Rating =[]\n",
    "\n",
    "#for loop for getting company name\n",
    "companyTag=driver.find_elements(By.XPATH,\"//p[@class='company body-medium']\")    \n",
    "for i in companyTag:\n",
    "    Company_Name.append(i.text)\n",
    "\n",
    " #for loop for no. of days ago when job was posted\n",
    "daytags=driver.find_elements(By.XPATH,\"//span[@class='body-small-l'][1]\")    \n",
    "for i in daytags:\n",
    "    Days.append(i.text)\n",
    " #for loop company rating   \n",
    "ratingtag=driver.find_elements(By.XPATH,\"//span[@class='body-small']\")     \n",
    "for i in ratingtag:\n",
    "    Rating.append(i.text)\n",
    "#Dataframe for creating table     \n",
    "df = pd.DataFrame({'Company Name':Company_Name,'No. of days ago when job was posted':Days,'Company Rating':Rating})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758127c0",
   "metadata": {},
   "source": [
    "# Q10: Write a python program to scrape the salary data for Data Scientist designation.You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary. \n",
    "The above task will be, done as shown in the below steps: \n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option as shown in the image. \n",
    "3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and \n",
    "then click on “Data Scientist”.\n",
    "You have to scrape the data ticked in the above image. \n",
    "4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average \n",
    "salary, minimum salary, maximum salary, experience required. \n",
    "5. Store the data in a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "307a6e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Administrator\\Downloads\\chromedriver.exe\")\n",
    "\n",
    "#specifiy the url of the webpage to be scrapped\n",
    "driver.get(\"https://www.ambitionbox.com/\")\n",
    "url=\"https://www.ambitionbox.com/salaries\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "29e10dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Number of salaries</th>\n",
       "      <th>Avgarage salary</th>\n",
       "      <th>Min salary</th>\n",
       "      <th>Max salary</th>\n",
       "      <th>Total Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Microsoft Corporation</td>\n",
       "      <td>based on 209 salaries</td>\n",
       "      <td>₹ 22.4L</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "      <td>₹ 45.0L</td>\n",
       "      <td>Software Engineer . 1-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>₹ 21.2L</td>\n",
       "      <td>₹ 16.0L</td>\n",
       "      <td>₹ 30.0L</td>\n",
       "      <td>Software Engineer . 2 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flipkart</td>\n",
       "      <td>based on 51 salaries</td>\n",
       "      <td>₹ 20.8L</td>\n",
       "      <td>₹ 7.0L</td>\n",
       "      <td>₹ 30.0L</td>\n",
       "      <td>Software Engineer . 1-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>based on 75 salaries</td>\n",
       "      <td>₹ 19.2L</td>\n",
       "      <td>₹ 8.0L</td>\n",
       "      <td>₹ 40.0L</td>\n",
       "      <td>Software Engineer . 1-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Servicenow Software Development India</td>\n",
       "      <td>based on 25 salaries</td>\n",
       "      <td>₹ 18.2L</td>\n",
       "      <td>₹ 13.0L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>Software Engineer . 2-3 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ServiceNow</td>\n",
       "      <td>based on 15 salaries</td>\n",
       "      <td>₹ 18.0L</td>\n",
       "      <td>₹ 11.2L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "      <td>Software Engineer . 3 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>based on 70 salaries</td>\n",
       "      <td>₹ 17.9L</td>\n",
       "      <td>₹ 10.0L</td>\n",
       "      <td>₹ 32.0L</td>\n",
       "      <td>Software Engineer . 1-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Arcesium</td>\n",
       "      <td>based on 54 salaries</td>\n",
       "      <td>₹ 17.7L</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "      <td>₹ 30.0L</td>\n",
       "      <td>Software Engineer . 1-2 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PayPal</td>\n",
       "      <td>based on 12 salaries</td>\n",
       "      <td>₹ 17.6L</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "      <td>Software Engineer . 1 yr exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Visa</td>\n",
       "      <td>based on 26 salaries</td>\n",
       "      <td>₹ 17.1L</td>\n",
       "      <td>₹ 13.0L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "      <td>Software Engineer . 1-2 yrs exp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Company Name     Number of salaries  \\\n",
       "0                  Microsoft Corporation  based on 209 salaries   \n",
       "1                          Goldman Sachs   based on 10 salaries   \n",
       "2                               Flipkart   based on 51 salaries   \n",
       "3                                 Amazon   based on 75 salaries   \n",
       "4  Servicenow Software Development India   based on 25 salaries   \n",
       "5                             ServiceNow   based on 15 salaries   \n",
       "6                                Walmart   based on 70 salaries   \n",
       "7                               Arcesium   based on 54 salaries   \n",
       "8                                 PayPal   based on 12 salaries   \n",
       "9                                   Visa   based on 26 salaries   \n",
       "\n",
       "  Avgarage salary Min salary Max salary                 Total Experience  \n",
       "0         ₹ 22.4L    ₹ 12.0L    ₹ 45.0L  Software Engineer . 1-4 yrs exp  \n",
       "1         ₹ 21.2L    ₹ 16.0L    ₹ 30.0L    Software Engineer . 2 yrs exp  \n",
       "2         ₹ 20.8L     ₹ 7.0L    ₹ 30.0L  Software Engineer . 1-4 yrs exp  \n",
       "3         ₹ 19.2L     ₹ 8.0L    ₹ 40.0L  Software Engineer . 1-4 yrs exp  \n",
       "4         ₹ 18.2L    ₹ 13.0L    ₹ 25.0L  Software Engineer . 2-3 yrs exp  \n",
       "5         ₹ 18.0L    ₹ 11.2L    ₹ 23.0L    Software Engineer . 3 yrs exp  \n",
       "6         ₹ 17.9L    ₹ 10.0L    ₹ 32.0L  Software Engineer . 1-4 yrs exp  \n",
       "7         ₹ 17.7L    ₹ 12.0L    ₹ 30.0L  Software Engineer . 1-2 yrs exp  \n",
       "8         ₹ 17.6L    ₹ 12.0L    ₹ 23.0L     Software Engineer . 1 yr exp  \n",
       "9         ₹ 17.1L    ₹ 13.0L    ₹ 23.0L  Software Engineer . 1-2 yrs exp  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating all empty list\n",
    "name=[]\n",
    "totalsalaryrecord=[]\n",
    "avg_salary=[]\n",
    "max_salary=[]\n",
    "min_salary=[]\n",
    "experience=[]\n",
    "#extracting URL for company name\n",
    "title_tags=driver.find_elements_by_xpath(\"//div[@class='name']/a\")\n",
    "# first 10 company names scraped using for loop\n",
    "for i in title_tags:\n",
    "    name.append(i.text)\n",
    "#extracting salary record for each company\n",
    "title_tags=driver.find_elements_by_xpath(\"//div[@class='name']/span\")\n",
    "\n",
    "#scrapping details of total salary record\n",
    "for i in title_tags:\n",
    "    totalsalaryrecord.append(i.text)\n",
    "\n",
    "#extracting URL for min salary\n",
    "\n",
    "title_tags=driver.find_elements_by_xpath(\"//div[@class='salary-values']/div[1]\")\n",
    "#scraping min salary for each company\n",
    "\n",
    "for i in title_tags:\n",
    "    min_salary.append(i.text)\n",
    "    \n",
    "\n",
    "#extracting URL for max salary\n",
    "title_tags=driver.find_elements_by_xpath(\"//div[@class='salary-values']/div[2]\")\n",
    "# scraping max salary for each company\n",
    "for i in title_tags:\n",
    "    max_salary.append(i.text)\n",
    "# extracting avg salary for each company\n",
    "title_tags=driver.find_elements_by_xpath(\"//p[@class='averageCtc']\")\n",
    "#scraping avg salary corroespond to each company\n",
    "for i in title_tags:\n",
    "    avg_salary.append(i.text)\n",
    "# extracting URL for total exp across each company required\n",
    "\n",
    "title_tags=driver.find_elements_by_xpath(\"//div[@class='salaries sbold-list-header']\")\n",
    "# scraping total exp\n",
    "for i in title_tags:\n",
    "    experience.append(i.text.replace(\"\\n\",\"\"))\n",
    "\n",
    "#Creating data frame \n",
    "jobs=pd.DataFrame({})\n",
    "jobs['Company Name']=name[0:10]\n",
    "jobs['Number of salaries']=totalsalaryrecord[0:10]\n",
    "jobs['Avgarage salary']=avg_salary[0:10]\n",
    "jobs['Min salary']=min_salary[0:10]\n",
    "jobs['Max salary']=max_salary[0:10]\n",
    "jobs['Total Experience']=experience[0:10]\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3910399",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
